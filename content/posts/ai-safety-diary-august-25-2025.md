---
title: "AI Safety Diary: August 25, 2025"
date: '2025-08-25T17:55:33+00:00'
categories:
  - "AI Safety"
tags:
  - "ai safety diary"
  - "effective altruism"
  - "existential risks"
  - "biosecurity"
  - "pandemics"
summary: "A diary entry on Chapter 4 of the Effective Altruism Handbook, 'Our Final Century?', which examines existential risks, particularly human-made pandemics, and strategies for biosecurity."
---

Today, I explored a chapter from the [Introduction to Effective Altruism Handbook](https://forum.effectivealtruism.org/handbook) as part of my AI safety and governance studies. Below is the resource I reviewed.

## Resource: Our Final Century?

- **Source**: [Our Final Century?](https://forum.effectivealtruism.org/s/vSAFjmWsfbMrTonpq), Effective Altruism Forum, Chapter 4 of the Introduction to Effective Altruism Handbook.
- **Summary**: This chapter examines existential risks that could destroy humanity’s long-term potential, emphasizing their moral priority and societal neglect. It focuses on risks like human-made pandemics worse than COVID-19 and discusses strategies for improving biosecurity to prevent catastrophic outcomes. The chapter introduces the concept of “expected value” to evaluate the impact of interventions and explores “hits-based giving,” where high-risk, high-reward approaches are prioritized. It also highlights the importance of identifying crucial considerations to avoid missing key factors that could undermine impact.