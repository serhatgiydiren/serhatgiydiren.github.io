<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>AI Alignment on Serhat Giydiren</title>
    <link>https://serhatgiydiren.com/categories/ai-alignment/</link>
    <description>Recent content in AI Alignment on Serhat Giydiren</description>
    <generator>Hugo -- 0.149.1</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 15 Aug 2025 12:40:49 +0000</lastBuildDate>
    <atom:link href="https://serhatgiydiren.com/categories/ai-alignment/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>AI Safety Diary: August 15, 2025</title>
      <link>https://serhatgiydiren.com/ai-safety-diary-august-15-2025/</link>
      <pubDate>Fri, 15 Aug 2025 12:40:49 +0000</pubDate>
      <guid>https://serhatgiydiren.com/ai-safety-diary-august-15-2025/</guid>
      <description>&lt;p&gt;Today, I continued exploring the &lt;a href=&#34;https://forum.effectivealtruism.org/handbook&#34;
   
   
   target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;
   &gt;Effective Altruism Handbook&lt;/a&gt;
 and completed its second chapter as part of my studies related to AI safety and governance. Below is the resource I reviewed.&lt;/p&gt;
&lt;h2 id=&#34;resource-differences-in-impact&#34;&gt;Resource: Differences in Impact&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Source&lt;/strong&gt;: &lt;a href=&#34;https://forum.effectivealtruism.org/s/x3KXkiAQ6NH8WLbkW&#34;
   
   
   target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;
   &gt;Differences in Impact&lt;/a&gt;
, Effective Altruism Forum, Chapter 2 of the Effective Altruism Handbook.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Summary&lt;/strong&gt;: This chapter focuses on the significant disparities in the effectiveness of interventions aimed at helping the approximately 700 million people living in poverty, primarily in low-income countries. It discusses strategies such as policy reform, cash transfers, and health service provision, emphasizing that some interventions are far more effective than others. The chapter introduces a simple tool for estimating key figures to evaluate impact and includes recommended readings, such as GiveWell&amp;rsquo;s &amp;ldquo;Giving 101&amp;rdquo; guide and sections on global health outcomes, to illustrate effective altruism approaches to addressing global poverty.&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    <item>
      <title>AI Safety Diary: August 14, 2025</title>
      <link>https://serhatgiydiren.com/ai-safety-diary-august-14-2025/</link>
      <pubDate>Thu, 14 Aug 2025 12:55:39 +0000</pubDate>
      <guid>https://serhatgiydiren.com/ai-safety-diary-august-14-2025/</guid>
      <description>&lt;p&gt;Today, I explored the &lt;a href=&#34;https://ai-safety-atlas.com/&#34;
   
   
   target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;
   &gt;AI Safety Atlas&lt;/a&gt;
 as part of my AI safety studies. Below is the resource I reviewed.&lt;/p&gt;
&lt;h2 id=&#34;resource-ai-safety-atlas-chapter-1-capabilities&#34;&gt;Resource: AI Safety Atlas (Chapter 1: Capabilities)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Source&lt;/strong&gt;: &lt;a href=&#34;https://youtu.be/J_iMeH1hb9M?si=Ds7buMC7off_dD8A&#34;
   
   
   target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;
   &gt;Chapter 1: Capabilities - Video Lecture (AI is Advancing Faster Than You Think! (AI Safety symposium 2/5))&lt;/a&gt;
, AI Safety Atlas by Markov Grey and Charbel-Raphaël Segerie et al., French Center for AI Safety (CeSIA), 2025.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Summary&lt;/strong&gt;: This chapter provides an overview of AI capabilities, focusing on the progression of modern AI systems toward artificial general intelligence (AGI). It discusses the increasing power of foundation models, such as large language models, and the importance of defining and measuring intelligence for safety purposes. The chapter explores challenges in defining intelligence, comparing approaches like the Turing Test, consciousness-based definitions, process-based adaptability, and a capabilities-focused framework. It emphasizes the latter, which assesses what AI systems can do, their performance levels, and the range of tasks they can handle, as the most practical for safety evaluations. The chapter also introduces frameworks for measuring AI progress on a continuous spectrum, moving beyond binary distinctions like narrow versus general AI, to better understand capabilities and associated risks.&lt;a href=&#34;https://ai-safety-atlas.com/chapters/01/03&#34;
   
   
   target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;
   &gt;&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    <item>
      <title>AI Safety Diary: August 13, 2025</title>
      <link>https://serhatgiydiren.com/ai-safety-diary-august-13-2025/</link>
      <pubDate>Wed, 13 Aug 2025 12:53:05 +0000</pubDate>
      <guid>https://serhatgiydiren.com/ai-safety-diary-august-13-2025/</guid>
      <description>&lt;p&gt;Today, I began the &lt;a href=&#34;https://bluedot.org/courses/alignment&#34;
   
   
   target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;
   &gt;BlueDot AI Alignment course&lt;/a&gt;
 and completed its first unit as part of my AI safety studies. Below is the resource I reviewed.&lt;/p&gt;
&lt;h2 id=&#34;resource-ai-and-the-years-ahead&#34;&gt;Resource: AI and the Years Ahead&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Source&lt;/strong&gt;: &lt;a href=&#34;https://bluedot.org/courses/alignment/1&#34;
   
   
   target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;
   &gt;Unit 1: AI and the Years Ahead&lt;/a&gt;
, BlueDot Impact AI Alignment Course.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Summary&lt;/strong&gt;: This unit introduces the foundational concepts of AI and its potential future impacts. It describes AI as a collection of approaches, focusing on key techniques like neural networks, gradient descent, and transformers used to train large language models (LLMs) such as ChatGPT. The unit explains how hardware advancements have driven AI progress and covers essential machine learning terms like weights, biases, parameters, neurons, and activations. It also explores the economic and non-economic incentives behind developing transformative AI systems and highlights recent advances in AI capabilities, providing a framework for understanding AI’s societal and economic implications.&lt;a href=&#34;https://bluedot.org/courses/alignment/1&#34;
   
   
   target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;
   &gt;&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    <item>
      <title>AI Safety Diary: August 10, 2025</title>
      <link>https://serhatgiydiren.com/ai-safety-diary-august-10-2025/</link>
      <pubDate>Sun, 10 Aug 2025 12:47:45 +0000</pubDate>
      <guid>https://serhatgiydiren.com/ai-safety-diary-august-10-2025/</guid>
      <description>&lt;p&gt;Today, I continued exploring the &lt;a href=&#34;https://aisafetybook.com&#34;
   
   
   target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;
   &gt;Introduction to AI Safety, Ethics, and Society&lt;/a&gt;
 textbook as part of my AI safety studies. Below is the resource I reviewed.&lt;/p&gt;
&lt;h2 id=&#34;resource-introduction-to-ai-safety-ethics-and-society-chapters-610-slides&#34;&gt;Resource: Introduction to AI Safety, Ethics, and Society (Chapters 6–10 Slides)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Source&lt;/strong&gt;: &lt;a href=&#34;https://aisafetybook.com&#34;
   
   
   target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;
   &gt;Introduction to AI Safety, Ethics, and Society&lt;/a&gt;
 by Dan Hendrycks, Taylor &amp;amp; Francis, 2024.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Summary&lt;/strong&gt;: The slides for chapters 6–10 of this textbook, developed by Dan Hendrycks, director of the Center for AI Safety, conclude the introduction to AI safety, ethics, and societal impacts. The chapters covered are:&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Chapter 6: Beneficial AI and Machine Ethics&lt;/strong&gt; - Explores the design of AI systems that align with human values and ethical principles, discussing frameworks for ensuring AI contributes positively to society.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Chapter 7: Collective Action Problems&lt;/strong&gt; - Examines challenges in coordinating AI development across stakeholders, addressing issues like competition and cooperation that impact safe AI deployment.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Chapter 8: Governance&lt;/strong&gt; - Covers approaches to AI governance, including safety standards, international treaties, and trade-offs between centralized and decentralized access to advanced AI systems.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Chapter 9: Appendix: Ethics&lt;/strong&gt; - Provides additional insights into ethical considerations for AI, focusing on moral frameworks and their application to AI decision-making.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Chapter 10: Appendix: Utility Functions&lt;/strong&gt; - Discusses the role of utility functions in AI systems, exploring how they shape AI behavior and the challenges of defining safe and effective objectives.&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    <item>
      <title>AI Safety Diary: August 9, 2025</title>
      <link>https://serhatgiydiren.com/ai-safety-diary-august-9-2025/</link>
      <pubDate>Sat, 09 Aug 2025 12:45:43 +0000</pubDate>
      <guid>https://serhatgiydiren.com/ai-safety-diary-august-9-2025/</guid>
      <description>&lt;p&gt;Today, I explored the &lt;a href=&#34;https://aisafetybook.com&#34;
   
   
   target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;
   &gt;Introduction to AI Safety, Ethics, and Society&lt;/a&gt;
 textbook as part of my AI safety studies. Below is the resource I reviewed.&lt;/p&gt;
&lt;h2 id=&#34;resource-introduction-to-ai-safety-ethics-and-society-chapters-15-slides&#34;&gt;Resource: Introduction to AI Safety, Ethics, and Society (Chapters 1–5 Slides)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Source&lt;/strong&gt;: &lt;a href=&#34;https://aisafetybook.com&#34;
   
   
   target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;
   &gt;Introduction to AI Safety, Ethics, and Society&lt;/a&gt;
 by Dan Hendrycks, Taylor &amp;amp; Francis, 2024.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Summary&lt;/strong&gt;: The slides for the first five chapters of this textbook, developed by Dan Hendrycks, director of the Center for AI Safety, provide an introduction to AI safety, ethics, and societal impacts. The chapters covered are:&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Chapter 1: Overview of Catastrophic AI Risks&lt;/strong&gt; - Introduces potential catastrophic risks from advanced AI, such as malicious use, accidents, and rogue AI systems.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Chapter 2: AI Fundamentals&lt;/strong&gt; - Covers the basics of modern AI systems, focusing on deep learning, transformer architectures, and scaling laws that drive AI performance.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Chapter 3: Single-Agent Safety&lt;/strong&gt; - Discusses technical challenges in ensuring the safety of individual AI systems, including issues like opaqueness, proxy gaming, and adversarial attacks.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Chapter 4: Safety Engineering&lt;/strong&gt; - Explores principles of safety engineering applied to AI, emphasizing methods to design robust and reliable AI systems.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Chapter 5: Complex Systems&lt;/strong&gt; - Examines AI within the context of complex sociotechnical systems, highlighting the role of systems theory in managing risks from AI deployment.&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    <item>
      <title>AI Safety Diary: August 8, 2025</title>
      <link>https://serhatgiydiren.com/ai-safety-diary-august-8-2025/</link>
      <pubDate>Fri, 08 Aug 2025 12:38:05 +0000</pubDate>
      <guid>https://serhatgiydiren.com/ai-safety-diary-august-8-2025/</guid>
      <description>&lt;p&gt;Today, I explored the &lt;a href=&#34;https://forum.effectivealtruism.org/handbook&#34;
   
   
   target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;
   &gt;Effective Altruism Handbook&lt;/a&gt;
 and completed its first chapter as part of my studies related to AI safety and governance. Below is the resource I reviewed.&lt;/p&gt;
&lt;h2 id=&#34;resource-the-effectiveness-mindset&#34;&gt;Resource: The Effectiveness Mindset&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Source&lt;/strong&gt;: &lt;a href=&#34;https://forum.effectivealtruism.org/s/B79ro5zkhndbBKRRX&#34;
   
   
   target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;
   &gt;The Effectiveness Mindset&lt;/a&gt;
, Effective Altruism Forum, Chapter 1 of the Effective Altruism Handbook.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Summary&lt;/strong&gt;: This chapter introduces the core idea of effective altruism: maximizing the impact of one&amp;rsquo;s time and resources to help others. It emphasizes the importance of focusing on interventions that benefit the most people, rather than those with lesser impact. The chapter highlights the challenge of identifying effective interventions, which requires a &amp;ldquo;scout mindset&amp;rdquo;—an approach focused on seeking truth and questioning existing ideas rather than defending preconceived notions.&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
  </channel>
</rss>
