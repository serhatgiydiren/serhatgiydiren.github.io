<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>AI Governance on Serhat Giydiren</title>
    <link>https://serhatgiydiren.com/categories/ai-governance/</link>
    <description>Recent content in AI Governance on Serhat Giydiren</description>
    <generator>Hugo -- 0.149.1</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 02 Oct 2025 19:00:00 +0300</lastBuildDate>
    <atom:link href="https://serhatgiydiren.com/categories/ai-governance/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>AI Safety Diary: October 2, 2025</title>
      <link>https://serhatgiydiren.com/ai-safety-diary-october-2-2025/</link>
      <pubDate>Thu, 02 Oct 2025 19:00:00 +0300</pubDate>
      <guid>https://serhatgiydiren.com/ai-safety-diary-october-2-2025/</guid>
      <description>A diary entry on the 8th chapter of the AI Safety Book, providing a deep dive into the challenges and potential solutions in AI governance, from corporate self-regulation to international treaties.</description>
    </item>
    <item>
      <title>AI Safety Diary: October 1, 2025</title>
      <link>https://serhatgiydiren.com/ai-safety-diary-october-1-2025/</link>
      <pubDate>Wed, 01 Oct 2025 19:00:00 +0300</pubDate>
      <guid>https://serhatgiydiren.com/ai-safety-diary-october-1-2025/</guid>
      <description>A diary entry on the 7th chapter of the AI Safety Book, which analyzes AI development through the lens of collective action problems, such as arms races and the tragedy of the commons.</description>
    </item>
    <item>
      <title>AI Safety Diary: September 25, 2025</title>
      <link>https://serhatgiydiren.com/ai-safety-diary-september-25-2025/</link>
      <pubDate>Thu, 25 Sep 2025 19:00:00 +0300</pubDate>
      <guid>https://serhatgiydiren.com/ai-safety-diary-september-25-2025/</guid>
      <description>A diary entry on the 4th chapter of the AI Safety Atlas, focusing on the critical area of AI governance and the challenges of creating effective policies and institutions to manage AI development globally.</description>
    </item>
    <item>
      <title>AI Safety Diary: September 14, 2025</title>
      <link>https://serhatgiydiren.com/ai-safety-diary-september-14-2025/</link>
      <pubDate>Sun, 14 Sep 2025 18:07:18 +0300</pubDate>
      <guid>https://serhatgiydiren.com/ai-safety-diary-september-14-2025/</guid>
      <description>Evaluates the ability of frontier LLMs to persuade users on harmful topics, assessing their strategies and the implications for AI safety and ethics.</description>
    </item>
    <item>
      <title>AI Safety Diary: September 13, 2025</title>
      <link>https://serhatgiydiren.com/ai-safety-diary-september-13-2025/</link>
      <pubDate>Sat, 13 Sep 2025 18:07:18 +0300</pubDate>
      <guid>https://serhatgiydiren.com/ai-safety-diary-september-13-2025/</guid>
      <description>Investigates how LLMs can be tuned to become more susceptible to jailbreaking, highlighting the implications for AI safety and the need for robust defenses.</description>
    </item>
    <item>
      <title>AI Safety Diary: September 8, 2025</title>
      <link>https://serhatgiydiren.com/ai-safety-diary-september-8-2025/</link>
      <pubDate>Mon, 08 Sep 2025 18:07:18 +0300</pubDate>
      <guid>https://serhatgiydiren.com/ai-safety-diary-september-8-2025/</guid>
      <description>A diary entry on common use cases for AI models and the risks of models obfuscating their reasoning to evade safety monitors.</description>
    </item>
    <item>
      <title>AI Safety Diary: September 2, 2025</title>
      <link>https://serhatgiydiren.com/ai-safety-diary-september-2-2025/</link>
      <pubDate>Tue, 02 Sep 2025 18:07:18 +0000</pubDate>
      <guid>https://serhatgiydiren.com/ai-safety-diary-september-2-2025/</guid>
      <description>A diary entry on Anthropic&amp;rsquo;s strategies for combating AI-enabled cybercrime, including threat intelligence, robust safety protocols, and collaboration to prevent misuse of AI systems.</description>
    </item>
    <item>
      <title>AI Safety Diary: August 29, 2025</title>
      <link>https://serhatgiydiren.com/ai-safety-diary-august-29-2025/</link>
      <pubDate>Fri, 29 Aug 2025 18:00:08 +0000</pubDate>
      <guid>https://serhatgiydiren.com/ai-safety-diary-august-29-2025/</guid>
      <description>A diary entry on AI governance strategies to avoid extinction risks, discussing catastrophic risks from misalignment, misuse, and geopolitical conflict, and the need for urgent research into governance mechanisms.</description>
    </item>
    <item>
      <title>AI Safety Diary: August 24, 2025</title>
      <link>https://serhatgiydiren.com/ai-safety-diary-august-24-2025/</link>
      <pubDate>Sun, 24 Aug 2025 17:51:12 +0000</pubDate>
      <guid>https://serhatgiydiren.com/ai-safety-diary-august-24-2025/</guid>
      <description>A diary entry on the audio version of Chapter 4 of the AI Safety Atlas, focusing on governance strategies for safe AI development, including safety standards, international treaties, and regulatory policies.</description>
    </item>
    <item>
      <title>AI Safety Diary: August 23, 2025</title>
      <link>https://serhatgiydiren.com/ai-safety-diary-august-23-2025/</link>
      <pubDate>Sat, 23 Aug 2025 17:50:12 +0000</pubDate>
      <guid>https://serhatgiydiren.com/ai-safety-diary-august-23-2025/</guid>
      <description>A diary entry on the audio version of Chapter 3 of the AI Safety Atlas, focusing on strategies for mitigating AI risks, including technical approaches like alignment and interpretability, and governance strategies.</description>
    </item>
    <item>
      <title>AI Safety Diary: August 19, 2025</title>
      <link>https://serhatgiydiren.com/ai-safety-diary-august-19-2025/</link>
      <pubDate>Tue, 19 Aug 2025 16:03:50 +0000</pubDate>
      <guid>https://serhatgiydiren.com/ai-safety-diary-august-19-2025/</guid>
      <description>A diary entry on the societal impacts of AI, including ethical concerns like bias and job displacement, and strategies for controlling powerful AI systems to ensure alignment and mitigate risks.</description>
    </item>
    <item>
      <title>AI Safety Diary: August 15, 2025</title>
      <link>https://serhatgiydiren.com/ai-safety-diary-august-15-2025/</link>
      <pubDate>Fri, 15 Aug 2025 12:40:49 +0000</pubDate>
      <guid>https://serhatgiydiren.com/ai-safety-diary-august-15-2025/</guid>
      <description>A diary entry on Chapter 2 of the Effective Altruism Handbook, focusing on the significant differences in the impact of interventions aimed at alleviating global poverty.</description>
    </item>
    <item>
      <title>AI Safety Diary: August 12, 2025</title>
      <link>https://serhatgiydiren.com/ai-safety-diary-august-12-2025/</link>
      <pubDate>Tue, 12 Aug 2025 12:24:42 +0000</pubDate>
      <guid>https://serhatgiydiren.com/ai-safety-diary-august-12-2025/</guid>
      <description>A diary entry summarizing several introductory resources on how AI learns, including machine learning concepts, Large Language Models (LLMs), and the progress of the deep learning revolution.</description>
    </item>
    <item>
      <title>AI Safety Diary: August 11, 2025</title>
      <link>https://serhatgiydiren.com/ai-safety-diary-august-11-2025/</link>
      <pubDate>Mon, 11 Aug 2025 20:36:43 +0000</pubDate>
      <guid>https://serhatgiydiren.com/ai-safety-diary-august-11-2025/</guid>
      <description>A diary entry on the &amp;lsquo;AI Triad&amp;rsquo; (algorithms, data, compute) and its implications for national security, based on the BlueDot AI Governance course.</description>
    </item>
    <item>
      <title>AI Safety Diary: August 10, 2025</title>
      <link>https://serhatgiydiren.com/ai-safety-diary-august-10-2025/</link>
      <pubDate>Sun, 10 Aug 2025 12:47:45 +0000</pubDate>
      <guid>https://serhatgiydiren.com/ai-safety-diary-august-10-2025/</guid>
      <description>A diary entry summarizing chapters 6-10 of the &amp;lsquo;Introduction to AI Safety, Ethics, and Society&amp;rsquo; textbook, covering beneficial AI, machine ethics, collective action problems, governance, and utility functions.</description>
    </item>
    <item>
      <title>AI Safety Diary: August 9, 2025</title>
      <link>https://serhatgiydiren.com/ai-safety-diary-august-9-2025/</link>
      <pubDate>Sat, 09 Aug 2025 12:45:43 +0000</pubDate>
      <guid>https://serhatgiydiren.com/ai-safety-diary-august-9-2025/</guid>
      <description>A diary entry summarizing chapters 1-5 of the &amp;lsquo;Introduction to AI Safety, Ethics, and Society&amp;rsquo; textbook, covering catastrophic AI risks, AI fundamentals, single-agent safety, safety engineering, and complex systems.</description>
    </item>
    <item>
      <title>AI Safety Diary: August 8, 2025</title>
      <link>https://serhatgiydiren.com/ai-safety-diary-august-8-2025/</link>
      <pubDate>Fri, 08 Aug 2025 12:38:05 +0000</pubDate>
      <guid>https://serhatgiydiren.com/ai-safety-diary-august-8-2025/</guid>
      <description>A diary entry on exploring the &amp;lsquo;Effectiveness Mindset&amp;rsquo; from the Effective Altruism Handbook, in the context of AI safety and governance.</description>
    </item>
  </channel>
</rss>
