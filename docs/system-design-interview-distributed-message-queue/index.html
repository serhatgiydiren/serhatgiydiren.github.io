<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>System Design Interview - Distributed Message Queue | Serhat Giydiren</title>
<meta name="keywords" content="system design, distributed systems, message queue, scalability, architecture, interview prep">
<meta name="description" content="A deep dive into designing a distributed message queue system. This guide covers core concepts from producers and consumers to advanced topics like delivery semantics (at-least-once, exactly-once), data partitioning, fault tolerance, and achieving high throughput.">
<meta name="author" content="">
<link rel="canonical" href="https://serhatgiydiren.com/system-design-interview-distributed-message-queue/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.08f7d74f0ada0f975d29ae436285b61ed7a719d05f350cb888d00341642995a2.css" integrity="sha256-CPfXTwraD5ddKa5DYoW2HtenGdBfNQy4iNADQWQplaI=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://serhatgiydiren.com/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://serhatgiydiren.com/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://serhatgiydiren.com/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://serhatgiydiren.com/apple-touch-icon.png">
<link rel="mask-icon" href="https://serhatgiydiren.com/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://serhatgiydiren.com/system-design-interview-distributed-message-queue/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
      <script async src="https://www.googletagmanager.com/gtag/js?id=G-RTZX9R4PB3"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-RTZX9R4PB3');
        }
      </script><meta property="og:url" content="https://serhatgiydiren.com/system-design-interview-distributed-message-queue/">
  <meta property="og:site_name" content="Serhat Giydiren">
  <meta property="og:title" content="System Design Interview - Distributed Message Queue">
  <meta property="og:description" content="A deep dive into designing a distributed message queue system. This guide covers core concepts from producers and consumers to advanced topics like delivery semantics (at-least-once, exactly-once), data partitioning, fault tolerance, and achieving high throughput.">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2021-03-04T09:25:27+00:00">
    <meta property="article:modified_time" content="2021-03-04T09:25:27+00:00">
    <meta property="article:tag" content="System Design">
    <meta property="article:tag" content="Distributed Systems">
    <meta property="article:tag" content="Message Queue">
    <meta property="article:tag" content="Scalability">
    <meta property="article:tag" content="Architecture">
    <meta property="article:tag" content="Interview Prep">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="System Design Interview - Distributed Message Queue">
<meta name="twitter:description" content="A deep dive into designing a distributed message queue system. This guide covers core concepts from producers and consumers to advanced topics like delivery semantics (at-least-once, exactly-once), data partitioning, fault tolerance, and achieving high throughput.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://serhatgiydiren.com/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "System Design Interview - Distributed Message Queue",
      "item": "https://serhatgiydiren.com/system-design-interview-distributed-message-queue/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "System Design Interview - Distributed Message Queue",
  "name": "System Design Interview - Distributed Message Queue",
  "description": "A deep dive into designing a distributed message queue system. This guide covers core concepts from producers and consumers to advanced topics like delivery semantics (at-least-once, exactly-once), data partitioning, fault tolerance, and achieving high throughput.",
  "keywords": [
    "system design", "distributed systems", "message queue", "scalability", "architecture", "interview prep"
  ],
  "articleBody": "For a curated list of system design interview resources, check out our Helpful Resources for System Design Interviews page.\nFor a comprehensive list of resources for tech interviews, check out our Best Resources for Tech Interviews page.\n1. Introduction: The Power of Asynchronous Communication In modern distributed systems, services need to communicate with each other. Synchronous communication (e.g., via direct API calls like REST or gRPC) is simple to implement initially but creates tight coupling. If the receiving service is slow, unresponsive, or down, the sending service is blocked, leading to cascading failures, increased latency, and reduced system resilience. This brittleness is a major liability at scale.\nMessage Queues are a foundational technology for building robust, scalable, and decoupled systems. They enable asynchronous communication: a service (the producer) sends a message to a queue without waiting for the recipient (the consumer) to process it. The message is stored durably in the queue, and the consumer can then retrieve and process it at its own pace. This acts as a buffer, smoothing out traffic spikes and allowing services to operate independently.\nA single-node message queue, however, quickly hits limitations:\nLimited Throughput: A single server can only handle a finite number of messages per second, becoming a bottleneck. Single Point of Failure (SPOF): If the server fails, the entire communication backbone of the application goes down, leading to service outages and potential message loss. Limited Storage: It can only store a limited number of messages, which can be problematic during consumer downtime or traffic surges. To overcome these, we build a Distributed Message Queue: a cluster of servers (brokers) that work together to provide a single, highly scalable, resilient, and durable messaging service. This guide explores the design of such a system in an interview context, focusing on the core principles and trade-offs.\n1.1 Why Distributed Message Queues? Distributed message queues offer several critical advantages for modern microservices and event-driven architectures:\nDecoupling: Producers and consumers don’t need to know about each other’s existence or availability. They only interact with the message queue. Asynchronous Processing: Long-running tasks can be offloaded to background workers, improving responsiveness of user-facing services. Load Leveling/Buffering: The queue absorbs bursts of traffic, protecting downstream services from being overwhelmed. Scalability: Easily scale producers and consumers independently by adding more instances. Reliability \u0026 Durability: Messages are persisted, ensuring they are not lost even if services crash. Fault Tolerance: The distributed nature ensures that the system remains operational even if individual nodes fail. Event-Driven Architectures: They are the backbone of event-driven systems, enabling services to react to events published by other services. 2. Core Concepts and Components Before diving into the design, let’s define the fundamental building blocks:\nMessage: The unit of data exchanged between services. A message typically consists of: Payload: The actual data (e.g., JSON, Protobuf, plain text). Headers/Metadata: Key-value pairs providing additional context (e.g., message type, timestamp, correlation ID, content type). Producer (Publisher): An application or service that creates and sends messages to the message queue. Consumer (Subscriber): An application or service that retrieves messages from the message queue and processes them. Broker (Server): The core component of the message queue system. Brokers receive messages from producers, store them, and deliver them to consumers. A distributed message queue consists of a cluster of brokers. Topic (or Queue/Channel): A named logical channel to which messages are published and from which consumers subscribe. Messages published to a topic are typically delivered to all interested subscribers (publish-subscribe model), while messages sent to a queue are usually consumed by only one consumer (point-to-point model). 3. Core Requirements and Design Goals Functional Requirements:\nPublish(topic, message): A producer sends a message to a specific topic. Subscribe(topic): A consumer subscribes to a topic to receive messages. Acknowledge(message): A consumer informs the queue that a message has been successfully processed, allowing the broker to mark it for deletion or commit its offset. Consume(topic, consumer_group_id): Consumers within the same group share the load of processing messages from a topic. Non-Functional Requirements:\nHigh Throughput: The system must handle a very large number of messages per second (from thousands to millions, depending on the use case). Low Latency: Messages should be delivered from producer to consumer with minimal delay. High Scalability: Must scale horizontally by adding more brokers and consumers to handle increased load and data volume. High Availability \u0026 Fault Tolerance: The system must remain operational and not lose messages even if some brokers or consumers fail. Durability: Once a message is accepted by the queue, it should not be lost, even in the event of system crashes. Tunable Delivery Semantics: The system should support different guarantees for message delivery (at-most-once, at-least-once, exactly-once). Message Ordering: Guaranteeing the order of messages, at least within a partition or for a specific key. Data Retention: Ability to retain messages for a configurable period, even after they are consumed. 4. High-Level Architecture At a high level, a distributed message queue system typically involves:\nProducers: Connect to brokers to send messages. Brokers: Form a cluster, store messages, and manage topics/partitions. Consumers: Connect to brokers to fetch and process messages. Metadata/Coordination Service: (e.g., ZooKeeper, etcd, or an internal Raft-based quorum) for managing cluster state, leader election, and storing metadata like topic configurations, partition assignments, and consumer offsets. 5. Core Challenge 1: Partitioning for Scalability and Ordering To achieve high throughput and enable parallel processing, a single topic must be spread across multiple brokers. This is done through partitioning (or sharding).\nA topic is divided into multiple partitions. Each partition is an independent, ordered, and immutable sequence of messages (a log). Each partition is managed by a single broker, which acts as the leader for that partition. When a producer sends a message to a topic, it must decide which partition to send it to. This can be done in several ways: Round-Robin: Distribute messages evenly across all partitions. This is good for load balancing but does not guarantee message ordering across the entire topic. Key-Based Partitioning: partition_index = hash(key) % num_partitions. The producer provides a key (e.g., user_id, order_id). All messages with the same key will go to the same partition. This is crucial as it guarantees message ordering for a given key within that partition. This is often the preferred method for maintaining logical order. Custom Partitioner: Producers can implement custom logic to determine the partition. By partitioning a topic, we can process messages in parallel across many brokers and consumers, allowing the system to scale horizontally. Consumers typically read from one or more partitions.\n5.1 Consumer Groups To allow multiple consumers to share the load of processing messages from a topic, consumer groups are used. All consumers within the same consumer group collectively consume messages from a topic’s partitions. Each partition is assigned to exactly one consumer within a group. This enables horizontal scaling of consumer applications.\nIf a consumer within a group fails, its assigned partitions are automatically reassigned to other consumers in the same group. If a new consumer joins a group, partitions are rebalanced among the group members. Different consumer groups can consume the same topic independently, each maintaining its own progress (offset). 6. Core Challenge 2: Durability and Storage How do brokers store messages to ensure they are not lost and can be retrieved reliably? Durability is paramount for most message queue use cases.\nIn-Memory Storage: Extremely fast but not durable. If a broker crashes, all messages it holds are lost. Unsuitable for most critical use cases. Disk-Based Storage: Messages are written to disk, providing durability. The main challenge is achieving high performance with disk I/O. Modern distributed message queues like Apache Kafka use a log-structured storage model for each partition. Each partition is an append-only log file on disk.\nWrites are extremely fast sequential appends to the end of the log. Sequential disk writes are significantly faster than random writes. Reads are also sequential (consumers read messages in order from a specific offset). This model leverages the operating system’s page cache for fast access while ensuring data is safely persisted on disk. Messages are typically flushed to disk periodically or after a certain number of messages. Message Offsets: Each message within a partition has a unique, monotonically increasing offset. Consumers track their progress by committing their last processed offset. This allows consumers to pause, restart, or even rewind to an earlier point in the log. Retention Policies: Messages are retained on disk for a configurable period (e.g., 7 days, 30 days) or until the partition size exceeds a certain limit. This allows consumers to catch up after downtime or for historical analysis. 7. Core Challenge 3: Delivery Semantics This is often the most critical part of the design discussion. What guarantee does the system provide about message delivery? This is a trade-off between reliability and performance.\n7.1 At-Most-Once Guarantee: A message is delivered zero or one time. The producer sends a message and does not retry if an acknowledgment is not received. The broker delivers the message to the consumer without waiting for an acknowledgment from the consumer. Pros: Highest throughput, lowest latency. Simplest to implement. Cons: Messages can be lost (e.g., due to network errors, broker crashes, or consumer crashes before processing). Suitable for non-critical data like metrics collection or real-time analytics where occasional data loss is acceptable. 7.2 At-Least-Once Guarantee: A message is delivered one or more times. The producer sends a message and waits for an acknowledgment (ACK) from the broker. If no ACK is received within a timeout, the producer retries sending the message. The consumer fetches a message, processes it, and then sends an ACK to the broker. If the broker doesn’t receive an ACK (e.g., the consumer crashes after processing but before acknowledging), it will redeliver the message. Pros: Guarantees that every message will eventually be delivered. Cons: Duplicate messages are possible. The consumer application must be idempotent (processing the same message multiple times has no additional side effects). This is the most common and practical semantic for many business-critical applications. Idempotency Example: If a message instructs to increment a user’s balance, simply re-executing it would lead to incorrect results. An idempotent approach would involve checking if the increment has already been applied using a unique message ID or a transaction ID. 7.3 Exactly-Once Guarantee: Each message is delivered and processed exactly one time, with no duplicates and no omissions. This is the “holy grail” of messaging and is extremely complex to achieve in a distributed system. It requires tight coordination and transactional guarantees across the producer, broker, and consumer. Mechanisms: Often involves a two-phase commit protocol or transactional APIs provided by the message queue (e.g., Kafka’s transactional producer and consumer). Producer Side: Ensures messages are written to the broker atomically, even if the producer crashes. Consumer Side: Ensures that message consumption and any downstream side effects (e.g., database updates) are committed atomically. If the consumer crashes, the entire operation is rolled back, and the message is re-processed. Pros: Strongest guarantee, ideal for financial transactions or critical data processing. Cons: Significantly lower throughput and higher latency due to the overhead of distributed transactions. High implementation complexity and operational overhead. 8. Ensuring High Availability: Replication What happens if a broker holding the leader partition for a topic fails? To prevent data loss and unavailability, we use replication.\nEach partition is replicated across multiple brokers (e.g., a replication factor of 3). This means each partition has a leader and several followers. One broker is the leader for the partition (handles all reads and writes from producers and consumers), and the others are followers (or replicas). Followers pull data from the leader to keep their copy of the partition log synchronized. If the leader broker fails, a coordination service (like ZooKeeper, or an internal Raft-based quorum in newer systems like Kafka’s KRaft) detects the failure and promotes one of the synchronized followers to be the new leader. The definition of “synchronized” is key. Systems like Kafka use an In-Sync Replica (ISR) list. A follower is in the ISR if it is not too far behind the leader. A write is only considered committed (and acknowledged to the producer) when all brokers in the ISR have acknowledged it. This ensures that committed messages are not lost if the leader fails. 8.1 Leader Election and Metadata Management For a distributed message queue to function, there must be a robust mechanism for:\nLeader Election: Electing a new leader for a partition when the current leader fails. Cluster Membership: Keeping track of which brokers are alive and part of the cluster. Configuration Management: Storing topic configurations, partition assignments, and consumer group offsets. Historically, systems like Kafka relied on Apache ZooKeeper for these tasks. Newer versions of Kafka are moving towards a built-in Raft-based consensus mechanism (KRaft) to remove the external dependency.\n9. Advanced Concepts and Challenges 9.1 Backpressure Management What happens if producers send messages faster than consumers can process them? This can lead to queues growing indefinitely, consuming excessive disk space, and increasing message latency.\nSolutions: Producer Throttling: Brokers can signal to producers to slow down if they are overwhelmed. Consumer Scaling: Automatically or manually scale up the number of consumers. Message Retention Policies: Configure the queue to automatically delete old messages after a certain time or size limit. 9.2 Dead-Letter Queues (DLQ) Messages that cannot be processed successfully after multiple retries (e.g., due to malformed data, application bugs, or transient errors) are typically moved to a Dead-Letter Queue. This prevents them from blocking the main queue and allows for manual inspection and reprocessing.\n9.3 Message Ordering Global Ordering: Extremely difficult and expensive to achieve in a high-throughput distributed system. Typically not provided. Partition-level Ordering: Guaranteed within a single partition. If messages for a specific entity (e.g., user_id) are always sent to the same partition, their order is preserved. 9.4 Schema Evolution As applications evolve, message formats change. How to handle this without breaking existing consumers?\nBackward Compatibility: New producers can send messages that old consumers can still understand (e.g., by adding optional fields). Forward Compatibility: Old producers can send messages that new consumers can understand (e.g., by ignoring unknown fields). Schema Registry: A centralized service (e.g., Confluent Schema Registry) that stores and manages message schemas (e.g., Avro, Protobuf). Producers register schemas, and consumers retrieve them, ensuring compatibility. 9.5 Security Authentication: Verify the identity of producers and consumers. Authorization: Control which producers can write to which topics and which consumers can read from them. Encryption: Encrypt messages in transit (TLS/SSL) and at rest (if the broker persists data to disk). 9.6 Monitoring and Alerting Robust monitoring is crucial for operational stability. Key metrics include:\nThroughput: Messages per second (in/out). Latency: End-to-end message delivery latency. Message Age: How long messages stay in the queue before being consumed. Consumer Lag: The difference between the latest message offset and the consumer’s committed offset (how far behind a consumer is). Disk Usage: On brokers. CPU/Memory/Network Utilization: For brokers and consumers. Error Rates: For produce and consume operations. 10. Real-World Use Cases Distributed message queues are integral to many modern system architectures:\nAsynchronous Task Processing: Offloading long-running tasks (e.g., image processing, email sending, report generation) to background workers. Event Sourcing: Storing a sequence of events that represent state changes in an application. Change Data Capture (CDC): Replicating database changes to other systems in real-time. Microservices Communication: Enabling loosely coupled communication between microservices. Log Aggregation: Collecting logs from various services into a centralized system. Stream Processing: Building real-time data pipelines and analytics (e.g., fraud detection, anomaly detection). User Activity Tracking: Capturing user clicks, views, and interactions for analytics. 11. Conclusion: A Game of Trade-offs Designing a distributed message queue is a masterclass in system design trade-offs:\nThroughput vs. Guarantees: Exactly-once semantics provide strong guarantees but come at the cost of performance. At-most-once is fast but lossy. At-least-once is a common, practical balance. Durability vs. Latency: Writing every message to disk synchronously is durable but slow. Asynchronous writes or relying on the page cache is faster but carries a small risk of data loss on a crash. Ordering vs. Load Balancing: Key-based partitioning provides ordering for a given key but can lead to “hot partitions” if one key is very active. Round-robin provides better load balancing but sacrifices ordering. Complexity vs. Features: Adding features like exactly-once semantics, schema evolution, or advanced monitoring significantly increases system complexity. In an interview, demonstrating your grasp of these core concepts—Partitioning, Durability, Delivery Semantics, and Replication—and your ability to reason about their trade-offs is the path to a successful design. Be prepared to discuss specific technologies (like Kafka, RabbitMQ, or cloud services) and how they implement these concepts. Also, consider edge cases, failure scenarios, and how to monitor the system effectively.\n",
  "wordCount" : "2771",
  "inLanguage": "en",
  "datePublished": "2021-03-04T09:25:27Z",
  "dateModified": "2021-03-04T09:25:27Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://serhatgiydiren.com/system-design-interview-distributed-message-queue/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Serhat Giydiren",
    "logo": {
      "@type": "ImageObject",
      "url": "https://serhatgiydiren.com/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://serhatgiydiren.com/" accesskey="h" title="Serhat Giydiren (Alt + H)">Serhat Giydiren</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://serhatgiydiren.com/archives" title="Archives">
                    <span>Archives</span>
                </a>
            </li>
            <li>
                <a href="https://serhatgiydiren.com/search" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://serhatgiydiren.com/tags" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="https://serhatgiydiren.com/categories" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      System Design Interview - Distributed Message Queue
    </h1>
    <div class="post-meta"><span title='2021-03-04 09:25:27 +0000 +0000'>March 4, 2021</span>&nbsp;·&nbsp;14 min

</div>
  </header> 
  <div class="post-content"><p>For a curated list of system design interview resources, check out our <a href="/helpful-resources-for-system-design-interviews"
   
   >Helpful Resources for System Design Interviews</a>
 page.</p>
<p>For a comprehensive list of resources for tech interviews, check out our <a href="/best-resources-for-tech-interviews"
   
   >Best Resources for Tech Interviews</a>
 page.</p>
<h2 id="1-introduction-the-power-of-asynchronous-communication">1. Introduction: The Power of Asynchronous Communication<a hidden class="anchor" aria-hidden="true" href="#1-introduction-the-power-of-asynchronous-communication">#</a></h2>
<p>In modern distributed systems, services need to communicate with each other. Synchronous communication (e.g., via direct API calls like REST or gRPC) is simple to implement initially but creates tight coupling. If the receiving service is slow, unresponsive, or down, the sending service is blocked, leading to cascading failures, increased latency, and reduced system resilience. This brittleness is a major liability at scale.</p>
<p><strong>Message Queues</strong> are a foundational technology for building robust, scalable, and decoupled systems. They enable asynchronous communication: a service (the <strong>producer</strong>) sends a message to a queue without waiting for the recipient (the <strong>consumer</strong>) to process it. The message is stored durably in the queue, and the consumer can then retrieve and process it at its own pace. This acts as a buffer, smoothing out traffic spikes and allowing services to operate independently.</p>
<p>A single-node message queue, however, quickly hits limitations:</p>
<ul>
<li><strong>Limited Throughput:</strong> A single server can only handle a finite number of messages per second, becoming a bottleneck.</li>
<li><strong>Single Point of Failure (SPOF):</strong> If the server fails, the entire communication backbone of the application goes down, leading to service outages and potential message loss.</li>
<li><strong>Limited Storage:</strong> It can only store a limited number of messages, which can be problematic during consumer downtime or traffic surges.</li>
</ul>
<p>To overcome these, we build a <strong>Distributed Message Queue</strong>: a cluster of servers (brokers) that work together to provide a single, highly scalable, resilient, and durable messaging service. This guide explores the design of such a system in an interview context, focusing on the core principles and trade-offs.</p>
<h3 id="11-why-distributed-message-queues">1.1 Why Distributed Message Queues?<a hidden class="anchor" aria-hidden="true" href="#11-why-distributed-message-queues">#</a></h3>
<p>Distributed message queues offer several critical advantages for modern microservices and event-driven architectures:</p>
<ul>
<li><strong>Decoupling:</strong> Producers and consumers don&rsquo;t need to know about each other&rsquo;s existence or availability. They only interact with the message queue.</li>
<li><strong>Asynchronous Processing:</strong> Long-running tasks can be offloaded to background workers, improving responsiveness of user-facing services.</li>
<li><strong>Load Leveling/Buffering:</strong> The queue absorbs bursts of traffic, protecting downstream services from being overwhelmed.</li>
<li><strong>Scalability:</strong> Easily scale producers and consumers independently by adding more instances.</li>
<li><strong>Reliability &amp; Durability:</strong> Messages are persisted, ensuring they are not lost even if services crash.</li>
<li><strong>Fault Tolerance:</strong> The distributed nature ensures that the system remains operational even if individual nodes fail.</li>
<li><strong>Event-Driven Architectures:</strong> They are the backbone of event-driven systems, enabling services to react to events published by other services.</li>
</ul>
<h2 id="2-core-concepts-and-components">2. Core Concepts and Components<a hidden class="anchor" aria-hidden="true" href="#2-core-concepts-and-components">#</a></h2>
<p>Before diving into the design, let&rsquo;s define the fundamental building blocks:</p>
<ul>
<li><strong>Message:</strong> The unit of data exchanged between services. A message typically consists of:
<ul>
<li><strong>Payload:</strong> The actual data (e.g., JSON, Protobuf, plain text).</li>
<li><strong>Headers/Metadata:</strong> Key-value pairs providing additional context (e.g., message type, timestamp, correlation ID, content type).</li>
</ul>
</li>
<li><strong>Producer (Publisher):</strong> An application or service that creates and sends messages to the message queue.</li>
<li><strong>Consumer (Subscriber):</strong> An application or service that retrieves messages from the message queue and processes them.</li>
<li><strong>Broker (Server):</strong> The core component of the message queue system. Brokers receive messages from producers, store them, and deliver them to consumers. A distributed message queue consists of a cluster of brokers.</li>
<li><strong>Topic (or Queue/Channel):</strong> A named logical channel to which messages are published and from which consumers subscribe. Messages published to a topic are typically delivered to all interested subscribers (publish-subscribe model), while messages sent to a queue are usually consumed by only one consumer (point-to-point model).</li>
</ul>
<h2 id="3-core-requirements-and-design-goals">3. Core Requirements and Design Goals<a hidden class="anchor" aria-hidden="true" href="#3-core-requirements-and-design-goals">#</a></h2>
<p><strong>Functional Requirements:</strong></p>
<ul>
<li><code>Publish(topic, message)</code>: A producer sends a message to a specific topic.</li>
<li><code>Subscribe(topic)</code>: A consumer subscribes to a topic to receive messages.</li>
<li><code>Acknowledge(message)</code>: A consumer informs the queue that a message has been successfully processed, allowing the broker to mark it for deletion or commit its offset.</li>
<li><code>Consume(topic, consumer_group_id)</code>: Consumers within the same group share the load of processing messages from a topic.</li>
</ul>
<p><strong>Non-Functional Requirements:</strong></p>
<ul>
<li><strong>High Throughput:</strong> The system must handle a very large number of messages per second (from thousands to millions, depending on the use case).</li>
<li><strong>Low Latency:</strong> Messages should be delivered from producer to consumer with minimal delay.</li>
<li><strong>High Scalability:</strong> Must scale horizontally by adding more brokers and consumers to handle increased load and data volume.</li>
<li><strong>High Availability &amp; Fault Tolerance:</strong> The system must remain operational and not lose messages even if some brokers or consumers fail.</li>
<li><strong>Durability:</strong> Once a message is accepted by the queue, it should not be lost, even in the event of system crashes.</li>
<li><strong>Tunable Delivery Semantics:</strong> The system should support different guarantees for message delivery (at-most-once, at-least-once, exactly-once).</li>
<li><strong>Message Ordering:</strong> Guaranteeing the order of messages, at least within a partition or for a specific key.</li>
<li><strong>Data Retention:</strong> Ability to retain messages for a configurable period, even after they are consumed.</li>
</ul>
<h2 id="4-high-level-architecture">4. High-Level Architecture<a hidden class="anchor" aria-hidden="true" href="#4-high-level-architecture">#</a></h2>
<p>At a high level, a distributed message queue system typically involves:</p>
<ul>
<li><strong>Producers:</strong> Connect to brokers to send messages.</li>
<li><strong>Brokers:</strong> Form a cluster, store messages, and manage topics/partitions.</li>
<li><strong>Consumers:</strong> Connect to brokers to fetch and process messages.</li>
<li><strong>Metadata/Coordination Service:</strong> (e.g., ZooKeeper, etcd, or an internal Raft-based quorum) for managing cluster state, leader election, and storing metadata like topic configurations, partition assignments, and consumer offsets.</li>
</ul>
<h2 id="5-core-challenge-1-partitioning-for-scalability-and-ordering">5. Core Challenge 1: Partitioning for Scalability and Ordering<a hidden class="anchor" aria-hidden="true" href="#5-core-challenge-1-partitioning-for-scalability-and-ordering">#</a></h2>
<p>To achieve high throughput and enable parallel processing, a single topic must be spread across multiple brokers. This is done through <strong>partitioning</strong> (or sharding).</p>
<ul>
<li>A topic is divided into multiple <strong>partitions</strong>. Each partition is an independent, ordered, and immutable sequence of messages (a log).</li>
<li>Each partition is managed by a single broker, which acts as the <strong>leader</strong> for that partition.</li>
<li>When a producer sends a message to a topic, it must decide which partition to send it to. This can be done in several ways:
<ul>
<li><strong>Round-Robin:</strong> Distribute messages evenly across all partitions. This is good for load balancing but <strong>does not guarantee message ordering</strong> across the entire topic.</li>
<li><strong>Key-Based Partitioning:</strong> <code>partition_index = hash(key) % num_partitions</code>. The producer provides a key (e.g., <code>user_id</code>, <code>order_id</code>). All messages with the same key will go to the same partition. This is crucial as it <strong>guarantees message ordering for a given key</strong> within that partition. This is often the preferred method for maintaining logical order.</li>
<li><strong>Custom Partitioner:</strong> Producers can implement custom logic to determine the partition.</li>
</ul>
</li>
</ul>
<p>By partitioning a topic, we can process messages in parallel across many brokers and consumers, allowing the system to scale horizontally. Consumers typically read from one or more partitions.</p>
<h3 id="51-consumer-groups">5.1 Consumer Groups<a hidden class="anchor" aria-hidden="true" href="#51-consumer-groups">#</a></h3>
<p>To allow multiple consumers to share the load of processing messages from a topic, <strong>consumer groups</strong> are used. All consumers within the same consumer group collectively consume messages from a topic&rsquo;s partitions. Each partition is assigned to exactly one consumer within a group. This enables horizontal scaling of consumer applications.</p>
<ul>
<li>If a consumer within a group fails, its assigned partitions are automatically reassigned to other consumers in the same group.</li>
<li>If a new consumer joins a group, partitions are rebalanced among the group members.</li>
<li>Different consumer groups can consume the same topic independently, each maintaining its own progress (offset).</li>
</ul>
<h2 id="6-core-challenge-2-durability-and-storage">6. Core Challenge 2: Durability and Storage<a hidden class="anchor" aria-hidden="true" href="#6-core-challenge-2-durability-and-storage">#</a></h2>
<p>How do brokers store messages to ensure they are not lost and can be retrieved reliably? Durability is paramount for most message queue use cases.</p>
<ul>
<li><strong>In-Memory Storage:</strong> Extremely fast but not durable. If a broker crashes, all messages it holds are lost. Unsuitable for most critical use cases.</li>
<li><strong>Disk-Based Storage:</strong> Messages are written to disk, providing durability. The main challenge is achieving high performance with disk I/O.</li>
</ul>
<p>Modern distributed message queues like Apache Kafka use a <strong>log-structured storage</strong> model for each partition. Each partition is an append-only log file on disk.</p>
<ul>
<li><strong>Writes</strong> are extremely fast sequential appends to the end of the log. Sequential disk writes are significantly faster than random writes.</li>
<li><strong>Reads</strong> are also sequential (consumers read messages in order from a specific offset).</li>
<li>This model leverages the operating system&rsquo;s page cache for fast access while ensuring data is safely persisted on disk. Messages are typically flushed to disk periodically or after a certain number of messages.</li>
<li><strong>Message Offsets:</strong> Each message within a partition has a unique, monotonically increasing offset. Consumers track their progress by committing their last processed offset. This allows consumers to pause, restart, or even rewind to an earlier point in the log.</li>
<li><strong>Retention Policies:</strong> Messages are retained on disk for a configurable period (e.g., 7 days, 30 days) or until the partition size exceeds a certain limit. This allows consumers to catch up after downtime or for historical analysis.</li>
</ul>
<h2 id="7-core-challenge-3-delivery-semantics">7. Core Challenge 3: Delivery Semantics<a hidden class="anchor" aria-hidden="true" href="#7-core-challenge-3-delivery-semantics">#</a></h2>
<p>This is often the most critical part of the design discussion. What guarantee does the system provide about message delivery? This is a trade-off between reliability and performance.</p>
<h4 id="71-at-most-once">7.1 At-Most-Once<a hidden class="anchor" aria-hidden="true" href="#71-at-most-once">#</a></h4>
<ul>
<li><strong>Guarantee:</strong> A message is delivered zero or one time. The producer sends a message and does not retry if an acknowledgment is not received. The broker delivers the message to the consumer without waiting for an acknowledgment from the consumer.</li>
<li><strong>Pros:</strong> Highest throughput, lowest latency. Simplest to implement.</li>
<li><strong>Cons:</strong> Messages can be lost (e.g., due to network errors, broker crashes, or consumer crashes before processing). Suitable for non-critical data like metrics collection or real-time analytics where occasional data loss is acceptable.</li>
</ul>
<h4 id="72-at-least-once">7.2 At-Least-Once<a hidden class="anchor" aria-hidden="true" href="#72-at-least-once">#</a></h4>
<ul>
<li><strong>Guarantee:</strong> A message is delivered one or more times. The producer sends a message and waits for an acknowledgment (ACK) from the broker. If no ACK is received within a timeout, the producer retries sending the message.</li>
<li>The consumer fetches a message, processes it, and then sends an ACK to the broker. If the broker doesn&rsquo;t receive an ACK (e.g., the consumer crashes after processing but before acknowledging), it will redeliver the message.</li>
<li><strong>Pros:</strong> Guarantees that every message will eventually be delivered.</li>
<li><strong>Cons:</strong> <strong>Duplicate messages</strong> are possible. The consumer application must be <strong>idempotent</strong> (processing the same message multiple times has no additional side effects). This is the most common and practical semantic for many business-critical applications.
<ul>
<li><strong>Idempotency Example:</strong> If a message instructs to increment a user&rsquo;s balance, simply re-executing it would lead to incorrect results. An idempotent approach would involve checking if the increment has already been applied using a unique message ID or a transaction ID.</li>
</ul>
</li>
</ul>
<h4 id="73-exactly-once">7.3 Exactly-Once<a hidden class="anchor" aria-hidden="true" href="#73-exactly-once">#</a></h4>
<ul>
<li><strong>Guarantee:</strong> Each message is delivered and processed exactly one time, with no duplicates and no omissions.</li>
<li>This is the &ldquo;holy grail&rdquo; of messaging and is extremely complex to achieve in a distributed system. It requires tight coordination and transactional guarantees across the producer, broker, and consumer.</li>
<li><strong>Mechanisms:</strong> Often involves a two-phase commit protocol or transactional APIs provided by the message queue (e.g., Kafka&rsquo;s transactional producer and consumer).
<ul>
<li><strong>Producer Side:</strong> Ensures messages are written to the broker atomically, even if the producer crashes.</li>
<li><strong>Consumer Side:</strong> Ensures that message consumption and any downstream side effects (e.g., database updates) are committed atomically. If the consumer crashes, the entire operation is rolled back, and the message is re-processed.</li>
</ul>
</li>
<li><strong>Pros:</strong> Strongest guarantee, ideal for financial transactions or critical data processing.</li>
<li><strong>Cons:</strong> Significantly lower throughput and higher latency due to the overhead of distributed transactions. High implementation complexity and operational overhead.</li>
</ul>
<h2 id="8-ensuring-high-availability-replication">8. Ensuring High Availability: Replication<a hidden class="anchor" aria-hidden="true" href="#8-ensuring-high-availability-replication">#</a></h2>
<p>What happens if a broker holding the leader partition for a topic fails? To prevent data loss and unavailability, we use <strong>replication</strong>.</p>
<ul>
<li>Each partition is replicated across multiple brokers (e.g., a replication factor of 3). This means each partition has a leader and several followers.</li>
<li>One broker is the <strong>leader</strong> for the partition (handles all reads and writes from producers and consumers), and the others are <strong>followers</strong> (or replicas).</li>
<li>Followers pull data from the leader to keep their copy of the partition log synchronized.</li>
<li>If the leader broker fails, a coordination service (like ZooKeeper, or an internal Raft-based quorum in newer systems like Kafka&rsquo;s KRaft) detects the failure and promotes one of the synchronized followers to be the new leader.</li>
<li>The definition of &ldquo;synchronized&rdquo; is key. Systems like Kafka use an <strong>In-Sync Replica (ISR)</strong> list. A follower is in the ISR if it is not too far behind the leader. A write is only considered committed (and acknowledged to the producer) when all brokers in the ISR have acknowledged it. This ensures that committed messages are not lost if the leader fails.</li>
</ul>
<h3 id="81-leader-election-and-metadata-management">8.1 Leader Election and Metadata Management<a hidden class="anchor" aria-hidden="true" href="#81-leader-election-and-metadata-management">#</a></h3>
<p>For a distributed message queue to function, there must be a robust mechanism for:</p>
<ul>
<li><strong>Leader Election:</strong> Electing a new leader for a partition when the current leader fails.</li>
<li><strong>Cluster Membership:</strong> Keeping track of which brokers are alive and part of the cluster.</li>
<li><strong>Configuration Management:</strong> Storing topic configurations, partition assignments, and consumer group offsets.</li>
</ul>
<p>Historically, systems like Kafka relied on Apache ZooKeeper for these tasks. Newer versions of Kafka are moving towards a built-in Raft-based consensus mechanism (KRaft) to remove the external dependency.</p>
<h2 id="9-advanced-concepts-and-challenges">9. Advanced Concepts and Challenges<a hidden class="anchor" aria-hidden="true" href="#9-advanced-concepts-and-challenges">#</a></h2>
<h4 id="91-backpressure-management">9.1 Backpressure Management<a hidden class="anchor" aria-hidden="true" href="#91-backpressure-management">#</a></h4>
<p>What happens if producers send messages faster than consumers can process them? This can lead to queues growing indefinitely, consuming excessive disk space, and increasing message latency.</p>
<ul>
<li><strong>Solutions:</strong>
<ul>
<li><strong>Producer Throttling:</strong> Brokers can signal to producers to slow down if they are overwhelmed.</li>
<li><strong>Consumer Scaling:</strong> Automatically or manually scale up the number of consumers.</li>
<li><strong>Message Retention Policies:</strong> Configure the queue to automatically delete old messages after a certain time or size limit.</li>
</ul>
</li>
</ul>
<h4 id="92-dead-letter-queues-dlq">9.2 Dead-Letter Queues (DLQ)<a hidden class="anchor" aria-hidden="true" href="#92-dead-letter-queues-dlq">#</a></h4>
<p>Messages that cannot be processed successfully after multiple retries (e.g., due to malformed data, application bugs, or transient errors) are typically moved to a <strong>Dead-Letter Queue</strong>. This prevents them from blocking the main queue and allows for manual inspection and reprocessing.</p>
<h4 id="93-message-ordering">9.3 Message Ordering<a hidden class="anchor" aria-hidden="true" href="#93-message-ordering">#</a></h4>
<ul>
<li><strong>Global Ordering:</strong> Extremely difficult and expensive to achieve in a high-throughput distributed system. Typically not provided.</li>
<li><strong>Partition-level Ordering:</strong> Guaranteed within a single partition. If messages for a specific entity (e.g., <code>user_id</code>) are always sent to the same partition, their order is preserved.</li>
</ul>
<h4 id="94-schema-evolution">9.4 Schema Evolution<a hidden class="anchor" aria-hidden="true" href="#94-schema-evolution">#</a></h4>
<p>As applications evolve, message formats change. How to handle this without breaking existing consumers?</p>
<ul>
<li><strong>Backward Compatibility:</strong> New producers can send messages that old consumers can still understand (e.g., by adding optional fields).</li>
<li><strong>Forward Compatibility:</strong> Old producers can send messages that new consumers can understand (e.g., by ignoring unknown fields).</li>
<li><strong>Schema Registry:</strong> A centralized service (e.g., Confluent Schema Registry) that stores and manages message schemas (e.g., Avro, Protobuf). Producers register schemas, and consumers retrieve them, ensuring compatibility.</li>
</ul>
<h4 id="95-security">9.5 Security<a hidden class="anchor" aria-hidden="true" href="#95-security">#</a></h4>
<ul>
<li><strong>Authentication:</strong> Verify the identity of producers and consumers.</li>
<li><strong>Authorization:</strong> Control which producers can write to which topics and which consumers can read from them.</li>
<li><strong>Encryption:</strong> Encrypt messages in transit (TLS/SSL) and at rest (if the broker persists data to disk).</li>
</ul>
<h4 id="96-monitoring-and-alerting">9.6 Monitoring and Alerting<a hidden class="anchor" aria-hidden="true" href="#96-monitoring-and-alerting">#</a></h4>
<p>Robust monitoring is crucial for operational stability. Key metrics include:</p>
<ul>
<li><strong>Throughput:</strong> Messages per second (in/out).</li>
<li><strong>Latency:</strong> End-to-end message delivery latency.</li>
<li><strong>Message Age:</strong> How long messages stay in the queue before being consumed.</li>
<li><strong>Consumer Lag:</strong> The difference between the latest message offset and the consumer&rsquo;s committed offset (how far behind a consumer is).</li>
<li><strong>Disk Usage:</strong> On brokers.</li>
<li><strong>CPU/Memory/Network Utilization:</strong> For brokers and consumers.</li>
<li><strong>Error Rates:</strong> For produce and consume operations.</li>
</ul>
<h2 id="10-real-world-use-cases">10. Real-World Use Cases<a hidden class="anchor" aria-hidden="true" href="#10-real-world-use-cases">#</a></h2>
<p>Distributed message queues are integral to many modern system architectures:</p>
<ul>
<li><strong>Asynchronous Task Processing:</strong> Offloading long-running tasks (e.g., image processing, email sending, report generation) to background workers.</li>
<li><strong>Event Sourcing:</strong> Storing a sequence of events that represent state changes in an application.</li>
<li><strong>Change Data Capture (CDC):</strong> Replicating database changes to other systems in real-time.</li>
<li><strong>Microservices Communication:</strong> Enabling loosely coupled communication between microservices.</li>
<li><strong>Log Aggregation:</strong> Collecting logs from various services into a centralized system.</li>
<li><strong>Stream Processing:</strong> Building real-time data pipelines and analytics (e.g., fraud detection, anomaly detection).</li>
<li><strong>User Activity Tracking:</strong> Capturing user clicks, views, and interactions for analytics.</li>
</ul>
<h2 id="11-conclusion-a-game-of-trade-offs">11. Conclusion: A Game of Trade-offs<a hidden class="anchor" aria-hidden="true" href="#11-conclusion-a-game-of-trade-offs">#</a></h2>
<p>Designing a distributed message queue is a masterclass in system design trade-offs:</p>
<ul>
<li><strong>Throughput vs. Guarantees:</strong> Exactly-once semantics provide strong guarantees but come at the cost of performance. At-most-once is fast but lossy. At-least-once is a common, practical balance.</li>
<li><strong>Durability vs. Latency:</strong> Writing every message to disk synchronously is durable but slow. Asynchronous writes or relying on the page cache is faster but carries a small risk of data loss on a crash.</li>
<li><strong>Ordering vs. Load Balancing:</strong> Key-based partitioning provides ordering for a given key but can lead to &ldquo;hot partitions&rdquo; if one key is very active. Round-robin provides better load balancing but sacrifices ordering.</li>
<li><strong>Complexity vs. Features:</strong> Adding features like exactly-once semantics, schema evolution, or advanced monitoring significantly increases system complexity.</li>
</ul>
<p>In an interview, demonstrating your grasp of these core concepts—<strong>Partitioning, Durability, Delivery Semantics, and Replication</strong>—and your ability to reason about their trade-offs is the path to a successful design. Be prepared to discuss specific technologies (like Kafka, RabbitMQ, or cloud services) and how they implement these concepts. Also, consider edge cases, failure scenarios, and how to monitor the system effectively.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://serhatgiydiren.com/tags/system-design/">System Design</a></li>
      <li><a href="https://serhatgiydiren.com/tags/distributed-systems/">Distributed Systems</a></li>
      <li><a href="https://serhatgiydiren.com/tags/message-queue/">Message Queue</a></li>
      <li><a href="https://serhatgiydiren.com/tags/scalability/">Scalability</a></li>
      <li><a href="https://serhatgiydiren.com/tags/architecture/">Architecture</a></li>
      <li><a href="https://serhatgiydiren.com/tags/interview-prep/">Interview Prep</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://serhatgiydiren.com/">Serhat Giydiren</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
