<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Ai Risks on Serhat Giydiren</title>
    <link>https://serhatgiydiren.com/tags/ai-risks/</link>
    <description>Recent content in Ai Risks on Serhat Giydiren</description>
    <generator>Hugo -- 0.149.1</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 17 Sep 2025 19:00:00 +0300</lastBuildDate>
    <atom:link href="https://serhatgiydiren.com/tags/ai-risks/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>AI Safety Diary: September 17, 2025</title>
      <link>https://serhatgiydiren.com/ai-safety-diary-september-17-2025/</link>
      <pubDate>Wed, 17 Sep 2025 19:00:00 +0300</pubDate>
      <guid>https://serhatgiydiren.com/ai-safety-diary-september-17-2025/</guid>
      <description>Watched the introductory lecture from the AI Safety Book series. The video provides a foundational overview of AI safety, discusses the ethical considerations, and outlines the landscape of potential risks associated with advanced AI.</description>
    </item>
    <item>
      <title>AI Safety Diary: August 22, 2025</title>
      <link>https://serhatgiydiren.com/ai-safety-diary-august-22-2025/</link>
      <pubDate>Fri, 22 Aug 2025 17:47:59 +0000</pubDate>
      <guid>https://serhatgiydiren.com/ai-safety-diary-august-22-2025/</guid>
      <description>A diary entry on the audio version of Chapter 2 of the AI Safety Atlas, focusing on various AI risks, including misuse, accidents, and systemic risks, and the challenges of alignment failures.</description>
    </item>
    <item>
      <title>AI Safety Diary: August 19, 2025</title>
      <link>https://serhatgiydiren.com/ai-safety-diary-august-19-2025/</link>
      <pubDate>Tue, 19 Aug 2025 16:03:50 +0000</pubDate>
      <guid>https://serhatgiydiren.com/ai-safety-diary-august-19-2025/</guid>
      <description>A diary entry on the societal impacts of AI, including ethical concerns like bias and job displacement, and strategies for controlling powerful AI systems to ensure alignment and mitigate risks.</description>
    </item>
  </channel>
</rss>
